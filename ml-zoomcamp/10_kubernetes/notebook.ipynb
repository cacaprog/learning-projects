{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 12:39:20.601639: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 12:39:21.255115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-01 12:39:21.255183: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-01 12:39:21.255188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• tf-serving makes use of gRPC, a framework for connecting services in and across datacenters. gRPC uses _Protocol Buffers_ (AKA _**Protobuf**_) for formatting data, a kind of binary encoding which is faster and more efficient than JSON.\n",
    "\n",
    "• The _stub_ is our interface with the tf-serving in order to make inference with our model. It needs a channel as a parameter to establish the communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost:8500'\n",
    "channel = grpc.insecure_channel(host)\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "prepocessor = create_preprocessor('xception', target_size=(299,299))\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = prepocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the image into a numpy array that our model can process\n",
    "\n",
    "def np_to_protobuf(data):\n",
    "    return tf.make_tensor_proto(data, shape=data.shape)\n",
    "\n",
    "pb_request = predict_pb2.PredictRequest()\n",
    "pb_request.model_spec.name = 'clothing-model'\n",
    "pb_request.model_spec.signature_name = 'serving_default'\n",
    "pb_request.inputs['input_8'].CopyFrom(np_to_protobuf(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set up our request to our model by instancing a Protobuf request object and defining its model name, the model's signature name that we saw before and its input.\n",
    "\n",
    "For the input, note that we make use of the input name that we found in the signature. We also convert the numpy array of our image to Protobuf format and copy it to the request object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_response = stub.Predict(pb_request, timeout=20.0)\n",
    "preds = pb_response.outputs['dense_7'].float_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8798645734786987,\n",
       " 'hat': -4.756311893463135,\n",
       " 'longsleeve': -2.3595333099365234,\n",
       " 'outwear': -1.0892642736434937,\n",
       " 'pants': 9.90378475189209,\n",
       " 'shirt': -2.826181173324585,\n",
       " 'shoes': -3.648310422897339,\n",
       " 'shorts': 3.2411563396453857,\n",
       " 'skirt': -2.612095832824707,\n",
       " 't-shirt': -4.852035999298096}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "dict(zip(classes, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Predict()` method returns a Protobuf response object. We can access our predictions with the name of the output that we found in the signature definition. `float_val` returns the predictions as a regular Python list, so there is no need to do additional conversions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlzc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
