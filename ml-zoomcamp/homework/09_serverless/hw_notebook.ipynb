{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 - What's the size of the converted model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 10:17:29.411700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 10:17:30.948022: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
      "2023-11-27 10:17:31.786163: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2023-11-27 10:17:31.786599: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-11-27 10:17:32.994914: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-11-27 10:17:32.994963: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('bees-wasps.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('bees-wasps.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 43M Nov 27 10:17 bees-wasps.tflite\n"
     ]
    }
   ],
   "source": [
    "ls -lh bees-wasps.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: What's the output index for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.lite as tflite\n",
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='bees-wasps.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg'\n",
    "\n",
    "img = download_image(url)\n",
    "\n",
    "img = prepare_image(img, (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.94509804, 0.90588235, 0.85882353],\n",
       "        [0.9372549 , 0.92156863, 0.97647059],\n",
       "        [0.91372549, 0.89803922, 0.95686275],\n",
       "        ...,\n",
       "        [0.29019608, 0.33333333, 0.16470588],\n",
       "        [0.34901961, 0.40784314, 0.15294118],\n",
       "        [0.29803922, 0.36078431, 0.11764706]],\n",
       "\n",
       "       [[0.94901961, 0.90980392, 0.87058824],\n",
       "        [0.91764706, 0.90980392, 0.96078431],\n",
       "        [0.90196078, 0.89411765, 0.94901961],\n",
       "        ...,\n",
       "        [0.2745098 , 0.3372549 , 0.16078431],\n",
       "        [0.47058824, 0.50588235, 0.18823529],\n",
       "        [0.45098039, 0.49411765, 0.18431373]],\n",
       "\n",
       "       [[0.92941176, 0.88235294, 0.81960784],\n",
       "        [0.91372549, 0.90980392, 0.96470588],\n",
       "        [0.90588235, 0.89411765, 0.96078431],\n",
       "        ...,\n",
       "        [0.32156863, 0.37647059, 0.17647059],\n",
       "        [0.50588235, 0.5254902 , 0.20392157],\n",
       "        [0.43137255, 0.46666667, 0.20392157]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.03137255, 0.06666667, 0.04705882],\n",
       "        [0.02352941, 0.08627451, 0.04705882],\n",
       "        [0.08235294, 0.08235294, 0.09019608],\n",
       "        ...,\n",
       "        [0.44313725, 0.36078431, 0.05098039],\n",
       "        [0.16862745, 0.17647059, 0.12156863],\n",
       "        [0.1254902 , 0.15686275, 0.11372549]],\n",
       "\n",
       "       [[0.03137255, 0.06666667, 0.04705882],\n",
       "        [0.07843137, 0.11764706, 0.08627451],\n",
       "        [0.05490196, 0.09803922, 0.0745098 ],\n",
       "        ...,\n",
       "        [0.32156863, 0.26666667, 0.0745098 ],\n",
       "        [0.12156863, 0.13333333, 0.10588235],\n",
       "        [0.09411765, 0.11372549, 0.09019608]],\n",
       "\n",
       "       [[0.01960784, 0.03921569, 0.02352941],\n",
       "        [0.08627451, 0.11372549, 0.08235294],\n",
       "        [0.10196078, 0.12156863, 0.09411765],\n",
       "        ...,\n",
       "        [0.16470588, 0.17647059, 0.10980392],\n",
       "        [0.13333333, 0.15686275, 0.11764706],\n",
       "        [0.09803922, 0.11764706, 0.09019608]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(img) * (1 / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: After the pre-processing, what's the value in the first pixel, the R channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    return x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94509804, 0.90588236, 0.85882354], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Now let's apply this model to this image. What's the output of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65898407]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the lambda code:\n",
    "1. convert the notebook to python using `jupyter nbconvert --to script hw_notebook.ipynb homework.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlzchw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
