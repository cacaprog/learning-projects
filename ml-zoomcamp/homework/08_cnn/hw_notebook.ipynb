{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74db1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Bee or Wasp? from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a1cb7",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d2bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory for train and test data\n",
    "train_ds = './data/train/'\n",
    "test_ds = './data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df563e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rescalling the images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches using train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_ds,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)\n",
    "\n",
    "# Flow test images in batches using train_datagen\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_ds,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7e5957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41e4337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01cc83",
   "metadata": {},
   "source": [
    "## Building CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb9cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:29:57.737458: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76b3bf",
   "metadata": {},
   "source": [
    "1. **Sequential Model**:\n",
    "   - The `Sequential` model is a linear stack of layers in Keras. It allows you to create models layer-by-layer in a step-by-step fashion.\n",
    "\n",
    "2. **Convolutional Layer (Conv2D)**:\n",
    "   - `Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3))`:\n",
    "     - This is the first layer of your network and a convolutional layer.\n",
    "     - It has 32 filters (or kernels), each of size 3x3. Filters are used to extract features from the input image.\n",
    "     - `activation='relu'` indicates that the Rectified Linear Unit (ReLU) function is used as an activation function. ReLU introduces non-linearity to the model, allowing it to learn more complex patterns.\n",
    "     - `input_shape=(150, 150, 3)` defines the shape of the input data: 150x150 pixels and 3 channels (assuming color images, typically RGB).\n",
    "\n",
    "3. **Max Pooling Layer (MaxPooling2D)**:\n",
    "   - `MaxPooling2D(2, 2)`:\n",
    "     - This layer reduces the spatial dimensions (width and height) of the input volume.\n",
    "     - It performs down-sampling by dividing the input into pools of size 2x2 and taking the maximum value of each pool. This helps reduce the number of parameters and computation in the network, and also controls overfitting.\n",
    "\n",
    "4. **Flattening (Flatten)**:\n",
    "   - `Flatten()`:\n",
    "     - This layer flattens the 2D arrays from the previous layers into a 1D vector. This step is necessary because the Dense layers expect 1D inputs.\n",
    "\n",
    "5. **Fully Connected Layer (Dense)**:\n",
    "   - `Dense(64, activation='relu')`:\n",
    "     - This is a fully connected layer with 64 neurons.\n",
    "     - It takes the flattened input and applies weights, biases, and the ReLU activation function. This layer allows the network to learn non-linear combinations of the high-level features extracted by the convolutional layers.\n",
    "\n",
    "6. **Output Layer (Dense)**:\n",
    "   - `Dense(1, activation='sigmoid')`:\n",
    "     - This is the output layer of the model with a single neuron.\n",
    "     - Since this is a binary classification problem (bee or wasp), one neuron is sufficient for output. \n",
    "     - The `sigmoid` activation function is used, which outputs a value between 0 and 1, representing the probability of one class (e.g., a bee). A value close to 1 indicates a high probability of the class, while a value close to 0 indicates a low probability.\n",
    "\n",
    "In summary, your model starts with a convolutional layer to extract features from the image, followed by max pooling to reduce dimensionality. Then, it flattens the output and uses dense layers to further process the data. The final output is obtained through a sigmoid activation function in the last dense layer, suitable for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68dcb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(learning_rate=0.002, momentum=0.8),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ab883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Number of Parameters in the Convolutional Layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f840d",
   "metadata": {},
   "source": [
    "Q2 Answer: 896"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acdad0",
   "metadata": {},
   "source": [
    "## Trainning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c612c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:30:10.238826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.6089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:30:38.512475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 31s 167ms/step - loss: 0.6512 - accuracy: 0.6089 - val_loss: 0.5874 - val_accuracy: 0.6874\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 33s 181ms/step - loss: 0.5634 - accuracy: 0.7068 - val_loss: 0.5818 - val_accuracy: 0.6765\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 31s 170ms/step - loss: 0.5189 - accuracy: 0.7514 - val_loss: 0.5422 - val_accuracy: 0.7331\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 31s 169ms/step - loss: 0.4969 - accuracy: 0.7637 - val_loss: 0.5827 - val_accuracy: 0.6972\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 31s 166ms/step - loss: 0.4631 - accuracy: 0.7917 - val_loss: 0.5387 - val_accuracy: 0.7462\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 32s 176ms/step - loss: 0.4485 - accuracy: 0.8045 - val_loss: 0.5036 - val_accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 32s 173ms/step - loss: 0.4191 - accuracy: 0.8213 - val_loss: 0.5032 - val_accuracy: 0.7636\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.3713 - accuracy: 0.8515 - val_loss: 0.5606 - val_accuracy: 0.7135\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 31s 169ms/step - loss: 0.3377 - accuracy: 0.8635 - val_loss: 0.4904 - val_accuracy: 0.7756\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 31s 166ms/step - loss: 0.3052 - accuracy: 0.8817 - val_loss: 0.4904 - val_accuracy: 0.7636\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "   # steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "   # validation_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "# Question 3: What is the median of training accuracy for all the epochs for this model?\n",
    "accuracies = history.history['accuracy']\n",
    "median_accuracy = np.median(accuracies).round(3)\n",
    "print(median_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a7e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6852636337280273,\n",
       "  0.6673799157142639,\n",
       "  0.6404879689216614,\n",
       "  0.6094634532928467,\n",
       "  0.5739327669143677,\n",
       "  0.5284214019775391,\n",
       "  0.49343734979629517,\n",
       "  0.47613582015037537,\n",
       "  0.44612228870391846,\n",
       "  0.43343669176101685],\n",
       " 'accuracy': [0.5499048233032227,\n",
       "  0.5722056031227112,\n",
       "  0.6293174028396606,\n",
       "  0.6619526743888855,\n",
       "  0.7068262100219727,\n",
       "  0.7489801645278931,\n",
       "  0.775088369846344,\n",
       "  0.7916780114173889,\n",
       "  0.8052760362625122,\n",
       "  0.8011966347694397],\n",
       " 'val_loss': [0.6636930704116821,\n",
       "  0.6285654902458191,\n",
       "  0.6288901567459106,\n",
       "  0.5801663398742676,\n",
       "  0.5542347431182861,\n",
       "  0.5648717880249023,\n",
       "  0.5618477463722229,\n",
       "  0.5200570821762085,\n",
       "  0.5260006189346313,\n",
       "  0.5290839672088623],\n",
       " 'val_accuracy': [0.5446622967720032,\n",
       "  0.6405228972434998,\n",
       "  0.5816993713378906,\n",
       "  0.6928104758262634,\n",
       "  0.7200435996055603,\n",
       "  0.7004357576370239,\n",
       "  0.7167755961418152,\n",
       "  0.7527233362197876,\n",
       "  0.7320261597633362,\n",
       "  0.7527233362197876]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5aecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.088\n"
     ]
    }
   ],
   "source": [
    "# Question 4: What is the standard deviation of training loss for all the epochs for this model?\n",
    "losses = history.history['loss']\n",
    "std_loss = np.std(losses).round(3)\n",
    "print(std_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7affd8e",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad45b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data generator with augmentations for the training set\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for the test set (without augmentations)\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create augmented training and regular test generators\n",
    "train_generator_augmented = train_datagen_augmented.flow_from_directory(\n",
    "    train_ds,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_ds,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d563dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 57.1059 - accuracy: 0.5102 - val_loss: 0.6904 - val_accuracy: 0.5370\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.6915 - accuracy: 0.5377 - val_loss: 0.6926 - val_accuracy: 0.5370\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 23s 124ms/step - loss: 0.6917 - accuracy: 0.5374 - val_loss: 0.6911 - val_accuracy: 0.5370\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.6908 - accuracy: 0.5374 - val_loss: 0.6906 - val_accuracy: 0.5370\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 23s 125ms/step - loss: 0.6909 - accuracy: 0.5374 - val_loss: 0.6905 - val_accuracy: 0.5370\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.6905 - accuracy: 0.5374 - val_loss: 0.6905 - val_accuracy: 0.5370\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 23s 124ms/step - loss: 0.6904 - accuracy: 0.5374 - val_loss: 0.6904 - val_accuracy: 0.5370\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 23s 124ms/step - loss: 0.6904 - accuracy: 0.5374 - val_loss: 0.6904 - val_accuracy: 0.5370\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.6903 - accuracy: 0.5374 - val_loss: 0.6904 - val_accuracy: 0.5370\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.6903 - accuracy: 0.5374 - val_loss: 0.6904 - val_accuracy: 0.5370\n"
     ]
    }
   ],
   "source": [
    "# Continue training the model for 10 more epochs\n",
    "history = model.fit(\n",
    "    train_generator_augmented,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969aa8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704\n"
     ]
    }
   ],
   "source": [
    "# Question 5: What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "test_losses = history.history['val_loss']\n",
    "mean_test_loss = np.mean(accuracies).round(3)\n",
    "print(mean_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0eea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537\n"
     ]
    }
   ],
   "source": [
    "# Question 6: What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "test_accuracies = history.history['val_accuracy']\n",
    "last_5_accuracies = test_accuracies[5:10]\n",
    "mean_last_5_acc = np.mean(last_5_accuracies).round(3)\n",
    "print(mean_last_5_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d3205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
