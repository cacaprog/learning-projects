{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74db1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:09:18.115265: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a1cb7",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d2bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory for train and test data\n",
    "train_ds = './data/train/'\n",
    "test_ds = './data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df563e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rescalling the images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches using train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_ds,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)\n",
    "\n",
    "# Flow test images in batches using train_datagen\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_ds,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7e5957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41e4337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bee': 0, 'wasp': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01cc83",
   "metadata": {},
   "source": [
    "## Building CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb9cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:09:19.299674: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76b3bf",
   "metadata": {},
   "source": [
    "1. **Sequential Model**:\n",
    "   - The `Sequential` model is a linear stack of layers in Keras. It allows you to create models layer-by-layer in a step-by-step fashion.\n",
    "\n",
    "2. **Convolutional Layer (Conv2D)**:\n",
    "   - `Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3))`:\n",
    "     - This is the first layer of your network and a convolutional layer.\n",
    "     - It has 32 filters (or kernels), each of size 3x3. Filters are used to extract features from the input image.\n",
    "     - `activation='relu'` indicates that the Rectified Linear Unit (ReLU) function is used as an activation function. ReLU introduces non-linearity to the model, allowing it to learn more complex patterns.\n",
    "     - `input_shape=(150, 150, 3)` defines the shape of the input data: 150x150 pixels and 3 channels (assuming color images, typically RGB).\n",
    "\n",
    "3. **Max Pooling Layer (MaxPooling2D)**:\n",
    "   - `MaxPooling2D(2, 2)`:\n",
    "     - This layer reduces the spatial dimensions (width and height) of the input volume.\n",
    "     - It performs down-sampling by dividing the input into pools of size 2x2 and taking the maximum value of each pool. This helps reduce the number of parameters and computation in the network, and also controls overfitting.\n",
    "\n",
    "4. **Flattening (Flatten)**:\n",
    "   - `Flatten()`:\n",
    "     - This layer flattens the 2D arrays from the previous layers into a 1D vector. This step is necessary because the Dense layers expect 1D inputs.\n",
    "\n",
    "5. **Fully Connected Layer (Dense)**:\n",
    "   - `Dense(64, activation='relu')`:\n",
    "     - This is a fully connected layer with 64 neurons.\n",
    "     - It takes the flattened input and applies weights, biases, and the ReLU activation function. This layer allows the network to learn non-linear combinations of the high-level features extracted by the convolutional layers.\n",
    "\n",
    "6. **Output Layer (Dense)**:\n",
    "   - `Dense(1, activation='sigmoid')`:\n",
    "     - This is the output layer of the model with a single neuron.\n",
    "     - Since this is a binary classification problem (bee or wasp), one neuron is sufficient for output. \n",
    "     - The `sigmoid` activation function is used, which outputs a value between 0 and 1, representing the probability of one class (e.g., a bee). A value close to 1 indicates a high probability of the class, while a value close to 0 indicates a low probability.\n",
    "\n",
    "In summary, your model starts with a convolutional layer to extract features from the image, followed by max pooling to reduce dimensionality. Then, it flattens the output and uses dense layers to further process the data. The final output is obtained through a sigmoid activation function in the last dense layer, suitable for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68dcb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(learning_rate=0.002, momentum=0.8),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ab883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Number of Parameters in the Convolutional Layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f840d",
   "metadata": {},
   "source": [
    "Q2 Answer: 896"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acdad0",
   "metadata": {},
   "source": [
    "## Trainning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c612c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:09:19.500727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.5825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:09:46.710721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 30s 161ms/step - loss: 0.6710 - accuracy: 0.5825 - val_loss: 0.6295 - val_accuracy: 0.6503\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 31s 167ms/step - loss: 0.6356 - accuracy: 0.6337 - val_loss: 0.6001 - val_accuracy: 0.6852\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.5980 - accuracy: 0.6804 - val_loss: 0.5716 - val_accuracy: 0.7135\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 0.5525 - accuracy: 0.7212 - val_loss: 0.5362 - val_accuracy: 0.7179\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 28s 153ms/step - loss: 0.5144 - accuracy: 0.7550 - val_loss: 0.5342 - val_accuracy: 0.7527\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 0.4924 - accuracy: 0.7710 - val_loss: 0.5257 - val_accuracy: 0.7440\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 29s 159ms/step - loss: 0.4581 - accuracy: 0.7949 - val_loss: 0.5325 - val_accuracy: 0.7440\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 0.4381 - accuracy: 0.8107 - val_loss: 0.5129 - val_accuracy: 0.7516\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 29s 157ms/step - loss: 0.4155 - accuracy: 0.8262 - val_loss: 0.4792 - val_accuracy: 0.7734\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 30s 162ms/step - loss: 0.3773 - accuracy: 0.8501 - val_loss: 0.4925 - val_accuracy: 0.7723\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "   # steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "   # validation_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624d4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763\n"
     ]
    }
   ],
   "source": [
    "# Question 3: What is the median of training accuracy for all the epochs for this model?\n",
    "accuracies = history.history['accuracy']\n",
    "median_accuracy = np.median(accuracies).round(3)\n",
    "print(median_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d92a7e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6710295677185059,\n",
       "  0.6355607509613037,\n",
       "  0.598028838634491,\n",
       "  0.5524823069572449,\n",
       "  0.5144400000572205,\n",
       "  0.4923674166202545,\n",
       "  0.4580841362476349,\n",
       "  0.4380904734134674,\n",
       "  0.4155271649360657,\n",
       "  0.37734392285346985],\n",
       " 'accuracy': [0.5825400948524475,\n",
       "  0.6336687803268433,\n",
       "  0.6804460287094116,\n",
       "  0.7212401628494263,\n",
       "  0.7549632787704468,\n",
       "  0.7710089683532715,\n",
       "  0.7949415445327759,\n",
       "  0.8107152581214905,\n",
       "  0.826216995716095,\n",
       "  0.8501495718955994],\n",
       " 'val_loss': [0.6294625401496887,\n",
       "  0.6001157164573669,\n",
       "  0.5715534687042236,\n",
       "  0.5361791253089905,\n",
       "  0.5342348217964172,\n",
       "  0.5256584882736206,\n",
       "  0.5324500799179077,\n",
       "  0.5129280686378479,\n",
       "  0.47923290729522705,\n",
       "  0.49249571561813354],\n",
       " 'val_accuracy': [0.6503267884254456,\n",
       "  0.6851851940155029,\n",
       "  0.7135076522827148,\n",
       "  0.7178649306297302,\n",
       "  0.7527233362197876,\n",
       "  0.7440087199211121,\n",
       "  0.7440087199211121,\n",
       "  0.7516340017318726,\n",
       "  0.7734204530715942,\n",
       "  0.772331178188324]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5aecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.093\n"
     ]
    }
   ],
   "source": [
    "# Question 4: What is the standard deviation of training loss for all the epochs for this model?\n",
    "losses = history.history['loss']\n",
    "std_loss = np.std(losses).round(3)\n",
    "print(std_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7affd8e",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad45b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data generator with augmentations for the training set\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for the test set (without augmentations)\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create augmented training and regular test generators\n",
    "train_generator_augmented = train_datagen_augmented.flow_from_directory(\n",
    "    train_ds,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_ds,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d563dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:15:23.553640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - ETA: 0s - loss: 916.6515 - accuracy: 0.5385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:16:02.881765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 42s 228ms/step - loss: 916.6515 - accuracy: 0.5385 - val_loss: 0.6883 - val_accuracy: 0.5392\n",
      "Epoch 2/10\n",
      "140/184 [=====================>........] - ETA: 9s - loss: 0.6970 - accuracy: 0.5370"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Continue training the model for 10 more epochs\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     train_generator_augmented,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtest_generator\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/my_repos/learning-projects/ml-zoomcamp/homework/08_cnn/hw_notebook.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlzchw/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue training the model for 10 more epochs\n",
    "history = model.fit(\n",
    "    train_generator_augmented,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969aa8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704\n"
     ]
    }
   ],
   "source": [
    "# Question 5: What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "test_losses = history.history['val_loss']\n",
    "mean_test_loss = np.mean(accuracies).round(3)\n",
    "print(mean_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0eea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537\n"
     ]
    }
   ],
   "source": [
    "# Question 6: What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "test_accuracies = history.history['val_accuracy']\n",
    "last_5_accuracies = test_accuracies[5:10]\n",
    "mean_last_5_acc = np.mean(last_5_accuracies).round(3)\n",
    "print(mean_last_5_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d3205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
