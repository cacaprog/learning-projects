{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning US Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just got hired as a Data Analyst at the Census Bureau, which collects census data and creates interesting visualizations and insights from it.\n",
    "\n",
    "The person who had your job before you left you all the data they had for the most recent census. It is in multiple `csv` files. They didn't use pandas, they would just look through these `csv` files manually whenever they wanted to find something. Sometimes they would copy and paste certain numbers into Excel to make charts.\n",
    "\n",
    "The thought of it makes you shiver. This is not scalable or repeatable.\n",
    "\n",
    "Your boss wants you to make some scatterplots and histograms by the end of the day. Can you get this data into `pandas` and into reasonable shape so that you can make these histograms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first visualization your boss wants you to make is a scatterplot that shows average income in a state vs proportion of women in that state.\n",
    "\n",
    "   Open some of the census `csv` files that came with the kit you downloaded. How are they named? What kind of information do they hold? Will they help us make this graph?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files are csv. 10 files, with similar name: \"states0\" to \"states9\".\n",
    "The file states0.csv have: State, TotalPop, Hispanic, White, Black, Native, Asian, Pacific, Income,GenderPop.\n",
    "With Income and GenderPop variables, I can calculate the average income vs. proportion of women in that state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. It will be easier to inspect this data once we have it in a DataFrame. You can't even call `.head()` on these `csv`s! How are you supposed to read them?\n",
    "\n",
    "   Using `glob`, loop through the census files available and load them into DataFrames. Then, concatenate all of those DataFrames together into one DataFrame, called something like `us_census`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = []\n",
    "\n",
    "# list of a possible matches for a pathname and save them as dataframe\n",
    "import glob\n",
    "for state in glob.glob('*.csv'):\n",
    "    states_df.append(pd.read_csv(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix the table, letÂ´s concat \n",
    "us_census = pd.concat(states_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         State  TotalPop Hispanic   White   Black Native  Asian  \\\n",
      "0           0          Ohio  11575977    3.67%  75.90%  16.21%  0.17%  1.62%   \n",
      "1           1      Oklahoma   3849733   10.08%  66.06%   8.31%  6.72%  1.80%   \n",
      "2           2        Oregon   3939233   11.44%  78.40%   1.73%  1.00%  3.59%   \n",
      "3           3  Pennsylvania  12779559    6.13%  77.38%  11.63%  0.12%  2.80%   \n",
      "4           4   Puerto Rico   3583073   98.89%   0.77%   0.09%  0.00%  0.08%   \n",
      "\n",
      "  Pacific       Income          GenderPop  \n",
      "0   0.02%  $49,655.25   5662893M_5913084F  \n",
      "1   0.11%  $48,100.85   1906944M_1942789F  \n",
      "2   0.35%  $54,271.90   1948453M_1990780F  \n",
      "3   0.02%  $56,170.46   6245344M_6534215F  \n",
      "4   0.00%  $20,720.54   1713860M_1869213F  \n"
     ]
    }
   ],
   "source": [
    "print(us_census.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>State</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>Income</th>\n",
       "      <th>GenderPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.67%</td>\n",
       "      <td>75.90%</td>\n",
       "      <td>5.68%</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>1.62%</td>\n",
       "      <td>0.02%</td>\n",
       "      <td>$49,655.25</td>\n",
       "      <td>5662893M_5913084F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.238516e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.722237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.588488e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.266040e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.030429e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.701414e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.303256e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.842146e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 State      TotalPop Hispanic   White  Black Native  Asian  \\\n",
       "count    60.000000    60  6.000000e+01       60      60     60     60     60   \n",
       "unique         NaN    51           NaN       50      51     50     39     49   \n",
       "top            NaN  Ohio           NaN    3.67%  75.90%  5.68%  0.12%  1.62%   \n",
       "freq           NaN     2           NaN        2       2      3      4      4   \n",
       "mean      2.500000   NaN  6.238516e+06      NaN     NaN    NaN    NaN    NaN   \n",
       "std       1.722237   NaN  6.588488e+06      NaN     NaN    NaN    NaN    NaN   \n",
       "min       0.000000   NaN  6.266040e+05      NaN     NaN    NaN    NaN    NaN   \n",
       "25%       1.000000   NaN  2.030429e+06      NaN     NaN    NaN    NaN    NaN   \n",
       "50%       2.500000   NaN  4.701414e+06      NaN     NaN    NaN    NaN    NaN   \n",
       "75%       4.000000   NaN  7.303256e+06      NaN     NaN    NaN    NaN    NaN   \n",
       "max       5.000000   NaN  3.842146e+07      NaN     NaN    NaN    NaN    NaN   \n",
       "\n",
       "       Pacific       Income          GenderPop  \n",
       "count       55           60                 60  \n",
       "unique      18           51                 51  \n",
       "top      0.02%  $49,655.25   5662893M_5913084F  \n",
       "freq        12            2                  2  \n",
       "mean       NaN          NaN                NaN  \n",
       "std        NaN          NaN                NaN  \n",
       "min        NaN          NaN                NaN  \n",
       "25%        NaN          NaN                NaN  \n",
       "50%        NaN          NaN                NaN  \n",
       "75%        NaN          NaN                NaN  \n",
       "max        NaN          NaN                NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_census.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60 entries, 0 to 5\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  60 non-null     int64 \n",
      " 1   State       60 non-null     object\n",
      " 2   TotalPop    60 non-null     int64 \n",
      " 3   Hispanic    60 non-null     object\n",
      " 4   White       60 non-null     object\n",
      " 5   Black       60 non-null     object\n",
      " 6   Native      60 non-null     object\n",
      " 7   Asian       60 non-null     object\n",
      " 8   Pacific     55 non-null     object\n",
      " 9   Income      60 non-null     object\n",
      " 10  GenderPop   60 non-null     object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "us_census.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns:\n",
    "- Pacific have 5 null\n",
    "- What is Unnamed? We should delete it?\n",
    "- Number and percentage are objects, except TotalPop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Look at the `.columns` and the `.dtypes` of the `us_census` DataFrame. Are those datatypes going to hinder you as you try to make histograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Look at the `head()` of the DataFrame so that you can understand why some of these `dtypes` are objects instead of integers or floats.\n",
    "\n",
    "   Start to make a plan for how to convert these columns into the right types for manipulation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to the right types:\n",
    "- eliminate % from numbers in columns >> float\n",
    "- Income >> int\n",
    "- GenderPop >> separete (M)ale and (F)emale >> int\n",
    "- TotalPop >> proportional int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex to the Rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use regex to turn the `Income` column into a format that is ready for conversion into a numerical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Look at the `GenderPop` column. We are going to want to separate this into two columns, the `Men` column, and the `Women` column.\n",
    "\n",
    "   Split the column into those two new columns using `str.split` and separating out those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Convert both of the columns into numerical datatypes.\n",
    "\n",
    "   There is still an `M` or an `F` character in each entry! We should remove those before we convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Now you should have the columns you need to make the graph and make sure your boss does not slam a ruler angrily on your desk because you've wasted your whole day cleaning your data with no results to show!\n",
    "\n",
    "   Use matplotlib to make a scatterplot!\n",
    "   \n",
    "   ```py\n",
    "   plt.scatter(the_women_column, the_income_column)\n",
    "   ```\n",
    "   \n",
    "   Remember to call `plt.show()` to see the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. You want to double check your work. You know from experience that these monstrous csv files probably have `nan` values in them! Print out your column with the number of women per state to see.\n",
    "\n",
    "   We can fill in those `nan`s by using pandas' `.fillna()` function.\n",
    "   \n",
    "   You have the `TotalPop` per state, and you have the `Men` per state. As an estimate for the `nan` values in the `Women` column, you could use the `TotalPop` of that state minus the `Men` for that state.\n",
    "   \n",
    "   Print out the `Women` column after filling the `nan` values to see if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. We forgot to check for duplicates! Use `.duplicated()` on your `census` DataFrame to see if we have duplicate rows in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Drop those duplicates using the `.drop_duplicates()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Make the scatterplot again. Now, it should be perfect! Your job is secure, for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Now your boss wants you to make a bunch of histograms out of the race data that you have. Look at the `.columns` again to see what the race categories are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Try to make a histogram for each one!\n",
    "\n",
    "    You will have to get the columns into the numerical format, and those percentage signs will have to go.\n",
    "    \n",
    "    Don't forget to fill the `nan` values with something that makes sense! You probably dropped the duplicate rows when making your last graph, but it couldn't hurt to check for duplicates again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Creative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Phew. You've definitely impressed your boss on your first day of work.\n",
    "\n",
    "    But is there a way you really convey the power of pandas and Python over the drudgery of `csv` and Excel?\n",
    "    \n",
    "    Try to make some more interesting graphs to show your boss, and the world! You may need to clean the data even more to do it, or the cleaning you have already done may give you the ease of manipulation you've been searching for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "155e4320cbd76e32fdde734bac67ea2e161d2b8f53e6edc9d7eae4ecf3146a98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
